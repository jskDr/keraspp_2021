{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 텐서플로 함수 활용하기  \n",
    "새로운 구능 기현시 유연하게 대처하는 방법으로 텐서플로와 케라스를 섞어 쓰는 방법을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set to use CPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.1 텐서플로와 케라스 패키지 임포트 및 상호 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.2 완전 연결층 인공지능망 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "\n",
    "class DNN():\n",
    "    def __init__(self, Nin, Nh_l, Nout):\n",
    "        self.X_ph = tf.placeholder(tf.float32, shape=(None, Nin))\n",
    "        self.L_ph = tf.placeholder(tf.float32, shape=(None, Nout))\n",
    "        \n",
    "        # Modeling\n",
    "        H = Dense(Nh_l[0], activation='relu')(self.X_ph)\n",
    "        H = Dropout(0.5)(H)\n",
    "        H = Dense(Nh_l[1], activation='relu')(H) \n",
    "        H = Dropout(0.25)(H)\n",
    "        self.Y_tf = Dense(Nout, activation='softmax')(H)\n",
    "        \n",
    "        # Operation\n",
    "        self.Loss_tf = tf.reduce_mean(\n",
    "            categorical_crossentropy(self.L_ph, self.Y_tf))\n",
    "        self.Train_tf = tf.train.AdamOptimizer().minimize(self.Loss_tf)\n",
    "        self.Acc_tf = categorical_accuracy(self.L_ph, self.Y_tf)\n",
    "        self.Init_tf = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.3 데이터 준비 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets  # mnist\n",
    "from keras.utils import np_utils  # to_categorical\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, W, H = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H)\n",
    "    X_test = X_test.reshape(-1, W * H)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5.4 학습 진행 및 효과 분석 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run(model, data, sess, epochs, batch_size=100):\n",
    "    # epochs = 2\n",
    "    # batch_size = 100\n",
    "    (X_train, Y_train), (X_test, Y_test) = data\n",
    "    sess.run(model.Init_tf)\n",
    "    with sess.as_default():\n",
    "        N_tr = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            for b in range(N_tr // batch_size):\n",
    "                X_tr_b = X_train[batch_size * (b-1):batch_size * b]\n",
    "                Y_tr_b = Y_train[batch_size * (b-1):batch_size * b]\n",
    "\n",
    "                model.Train_tf.run(feed_dict={model.X_ph: X_tr_b, model.L_ph: Y_tr_b, K.learning_phase(): 1})\n",
    "            loss = sess.run(model.Loss_tf, feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            acc = model.Acc_tf.eval(feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            print(\"Epoch {0}: loss = {1:.3f}, acc = {2:.3f}\".format(epoch, loss, np.mean(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.5 주 함수 구현 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_520/2708603483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_520/2708603483.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNh_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_520/2151237096.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, Nin, Nh_l, Nout)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNh_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    Nin = 784\n",
    "    Nh_l = [100, 50]\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class\n",
    "\n",
    "    data = Data_func()\n",
    "    model = DNN(Nin, Nh_l, Nout)\n",
    "\n",
    "    run(model, data, sess, 10, 100)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 9.2.7 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: [5 7 9]\n",
      "Predictions: [4.9328327 6.8842306 8.835628 ]\n",
      "Errors: [0.06716728 0.11576939 0.16437244]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "# 분류 DNN 모델 구현 ########################\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "\n",
    "class DNN():\n",
    "    def __init__(self, Nin, Nh_l, Nout):\n",
    "        self.X_ph = tf.placeholder(tf.float32, shape=(None, Nin))\n",
    "        self.L_ph = tf.placeholder(tf.float32, shape=(None, Nout))\n",
    "        \n",
    "        # Modeling\n",
    "        H = Dense(Nh_l[0], activation='relu')(self.X_ph)\n",
    "        H = Dropout(0.5)(H)\n",
    "        H = Dense(Nh_l[1], activation='relu')(H) \n",
    "        H = Dropout(0.25)(H)\n",
    "        self.Y_tf = Dense(Nout, activation='softmax')(H)\n",
    "        \n",
    "        # Operation\n",
    "        self.Loss_tf = tf.reduce_mean(\n",
    "            categorical_crossentropy(self.L_ph, self.Y_tf))\n",
    "        self.Train_tf = tf.train.AdamOptimizer().minimize(self.Loss_tf)\n",
    "        self.Acc_tf = categorical_accuracy(self.L_ph, self.Y_tf)\n",
    "        self.Init_tf = tf.global_variables_initializer()\n",
    "\n",
    "# 데이터 준비 ##############################\n",
    "import numpy as np\n",
    "from keras import datasets  # mnist\n",
    "from keras.utils import np_utils  # to_categorical\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, W, H = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H)\n",
    "    X_test = X_test.reshape(-1, W * H)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "\n",
    "# 학습 효과 분석 ##############################\n",
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run(model, data, sess, epochs, batch_size=100):\n",
    "    # epochs = 2\n",
    "    # batch_size = 100\n",
    "    (X_train, Y_train), (X_test, Y_test) = data\n",
    "    sess.run(model.Init_tf)\n",
    "    with sess.as_default():\n",
    "        N_tr = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            for b in range(N_tr // batch_size):\n",
    "                X_tr_b = X_train[batch_size * (b-1):batch_size * b]\n",
    "                Y_tr_b = Y_train[batch_size * (b-1):batch_size * b]\n",
    "\n",
    "                model.Train_tf.run(feed_dict={model.X_ph: X_tr_b, model.L_ph: Y_tr_b, K.learning_phase(): 1})\n",
    "            loss = sess.run(model.Loss_tf, feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            acc = model.Acc_tf.eval(feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            print(\"Epoch {0}: loss = {1:.3f}, acc = {2:.3f}\".format(epoch, loss, np.mean(acc)))\n",
    "\n",
    "# 분류 DNN 학습 및 테스팅 ####################\n",
    "def main():\n",
    "    Nin = 784\n",
    "    Nh_l = [100, 50]\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class\n",
    "\n",
    "    data = Data_func()\n",
    "    model = DNN(Nin, Nh_l, Nout)\n",
    "\n",
    "    run(model, data, sess, 10, 100)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
