{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 텐서플로 함수 활용하기  \n",
    "새로운 구능 기현시 유연하게 대처하는 방법으로 텐서플로와 케라스를 섞어 쓰는 방법을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sjkim/anaconda3/envs/keras206/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sjkim/anaconda3/envs/keras206/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sjkim/anaconda3/envs/keras206/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sjkim/anaconda3/envs/keras206/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sjkim/anaconda3/envs/keras206/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sjkim/anaconda3/envs/keras206/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set to use CPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.1 텐서플로와 케라스 패키지 임포트 및 상호 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.2 완전 연결층 인공지능망 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "\n",
    "class DNN():\n",
    "    def __init__(self, Nin, Nh_l, Nout):\n",
    "        self.X_ph = tf.placeholder(tf.float32, shape=(None, Nin))\n",
    "        self.L_ph = tf.placeholder(tf.float32, shape=(None, Nout))\n",
    "        \n",
    "        # Modeling\n",
    "        H = Dense(Nh_l[0], activation='relu')(self.X_ph)\n",
    "        H = Dropout(0.5)(H)\n",
    "        H = Dense(Nh_l[1], activation='relu')(H) \n",
    "        H = Dropout(0.25)(H)\n",
    "        self.Y_tf = Dense(Nout, activation='softmax')(H)\n",
    "        \n",
    "        # Operation\n",
    "        self.Loss_tf = tf.reduce_mean(\n",
    "            categorical_crossentropy(self.L_ph, self.Y_tf))\n",
    "        self.Train_tf = tf.train.AdamOptimizer().minimize(self.Loss_tf)\n",
    "        self.Acc_tf = categorical_accuracy(self.L_ph, self.Y_tf)\n",
    "        self.Init_tf = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.3 데이터 준비 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets  # mnist\n",
    "from keras.utils import np_utils  # to_categorical\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, W, H = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H)\n",
    "    X_test = X_test.reshape(-1, W * H)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5.4 학습 진행 및 효과 분석 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run(model, data, sess, epochs, batch_size=100):\n",
    "    # epochs = 2\n",
    "    # batch_size = 100\n",
    "    (X_train, Y_train), (X_test, Y_test) = data\n",
    "    sess.run(model.Init_tf)\n",
    "    with sess.as_default():\n",
    "        N_tr = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            for b in range(N_tr // batch_size):\n",
    "                X_tr_b = X_train[batch_size * (b-1):batch_size * b]\n",
    "                Y_tr_b = Y_train[batch_size * (b-1):batch_size * b]\n",
    "\n",
    "                model.Train_tf.run(feed_dict={model.X_ph: X_tr_b, model.L_ph: Y_tr_b, K.learning_phase(): 1})\n",
    "            loss = sess.run(model.Loss_tf, feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            acc = model.Acc_tf.eval(feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            print(\"Epoch {0}: loss = {1:.3f}, acc = {2:.3f}\".format(epoch, loss, np.mean(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.5 주 함수 구현 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sjkim/anaconda3/envs/keras206/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 0: loss = 0.224, acc = 0.932\n",
      "Epoch 1: loss = 0.173, acc = 0.947\n",
      "Epoch 2: loss = 0.152, acc = 0.954\n",
      "Epoch 3: loss = 0.143, acc = 0.958\n",
      "Epoch 4: loss = 0.133, acc = 0.961\n",
      "Epoch 5: loss = 0.124, acc = 0.965\n",
      "Epoch 6: loss = 0.114, acc = 0.966\n",
      "Epoch 7: loss = 0.115, acc = 0.968\n",
      "Epoch 8: loss = 0.109, acc = 0.968\n",
      "Epoch 9: loss = 0.113, acc = 0.967\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    Nin = 784\n",
    "    Nh_l = [100, 50]\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class\n",
    "\n",
    "    data = Data_func()\n",
    "    model = DNN(Nin, Nh_l, Nout)\n",
    "\n",
    "    run(model, data, sess, 10, 100)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 9.2.7 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.229, acc = 0.932\n",
      "Epoch 1: loss = 0.177, acc = 0.946\n",
      "Epoch 2: loss = 0.154, acc = 0.954\n",
      "Epoch 3: loss = 0.137, acc = 0.960\n",
      "Epoch 4: loss = 0.125, acc = 0.963\n",
      "Epoch 5: loss = 0.123, acc = 0.965\n",
      "Epoch 6: loss = 0.116, acc = 0.966\n",
      "Epoch 7: loss = 0.113, acc = 0.969\n",
      "Epoch 8: loss = 0.112, acc = 0.968\n",
      "Epoch 9: loss = 0.108, acc = 0.968\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "# 분류 DNN 모델 구현 ########################\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "\n",
    "class DNN():\n",
    "    def __init__(self, Nin, Nh_l, Nout):\n",
    "        self.X_ph = tf.placeholder(tf.float32, shape=(None, Nin))\n",
    "        self.L_ph = tf.placeholder(tf.float32, shape=(None, Nout))\n",
    "        \n",
    "        # Modeling\n",
    "        H = Dense(Nh_l[0], activation='relu')(self.X_ph)\n",
    "        H = Dropout(0.5)(H)\n",
    "        H = Dense(Nh_l[1], activation='relu')(H) \n",
    "        H = Dropout(0.25)(H)\n",
    "        self.Y_tf = Dense(Nout, activation='softmax')(H)\n",
    "        \n",
    "        # Operation\n",
    "        self.Loss_tf = tf.reduce_mean(\n",
    "            categorical_crossentropy(self.L_ph, self.Y_tf))\n",
    "        self.Train_tf = tf.train.AdamOptimizer().minimize(self.Loss_tf)\n",
    "        self.Acc_tf = categorical_accuracy(self.L_ph, self.Y_tf)\n",
    "        self.Init_tf = tf.global_variables_initializer()\n",
    "\n",
    "# 데이터 준비 ##############################\n",
    "import numpy as np\n",
    "from keras import datasets  # mnist\n",
    "from keras.utils import np_utils  # to_categorical\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, W, H = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H)\n",
    "    X_test = X_test.reshape(-1, W * H)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "\n",
    "# 학습 효과 분석 ##############################\n",
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run(model, data, sess, epochs, batch_size=100):\n",
    "    # epochs = 2\n",
    "    # batch_size = 100\n",
    "    (X_train, Y_train), (X_test, Y_test) = data\n",
    "    sess.run(model.Init_tf)\n",
    "    with sess.as_default():\n",
    "        N_tr = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            for b in range(N_tr // batch_size):\n",
    "                X_tr_b = X_train[batch_size * (b-1):batch_size * b]\n",
    "                Y_tr_b = Y_train[batch_size * (b-1):batch_size * b]\n",
    "\n",
    "                model.Train_tf.run(feed_dict={model.X_ph: X_tr_b, model.L_ph: Y_tr_b, K.learning_phase(): 1})\n",
    "            loss = sess.run(model.Loss_tf, feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            acc = model.Acc_tf.eval(feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            print(\"Epoch {0}: loss = {1:.3f}, acc = {2:.3f}\".format(epoch, loss, np.mean(acc)))\n",
    "\n",
    "# 분류 DNN 학습 및 테스팅 ####################\n",
    "def main():\n",
    "    Nin = 784\n",
    "    Nh_l = [100, 50]\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class\n",
    "\n",
    "    data = Data_func()\n",
    "    model = DNN(Nin, Nh_l, Nout)\n",
    "\n",
    "    run(model, data, sess, 10, 100)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras2",
   "language": "python",
   "name": "keras2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
