{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8장. 케라스2로 구현하는 UNET(유넷)\n",
    "유넷UNET은 저차원과 고차원 정보를 모두 사용하여 이미지의 특징을 추출하는 인공신경망이다.\n",
    "\n",
    "### 8.2 UNET을 이용한 컬러 복원 처리   \n",
    "UNET을 이용하여 흑백 이미지를 컬러 이미지로 복원하는 예제를 다룸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to use CPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.1 패키지 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import models, backend\n",
    "#from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Activation\n",
    "#from keras.layers import UpSampling2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import models, backend\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, BatchNormalization, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 UNET 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(models.Model):\n",
    "    def __init__(self, org_shape, n_ch):\n",
    "        ic = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "        def conv(x, n_f, mp_flag=True):\n",
    "            x = MaxPooling2D((2, 2), padding='same')(x) if mp_flag else x\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            x = Dropout(0.05)(x)\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            return x\n",
    "\n",
    "        def deconv_unet(x, e, n_f):\n",
    "            x = UpSampling2D((2, 2))(x)\n",
    "            x = Concatenate(axis=ic)([x, e])\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            return x\n",
    "\n",
    "        # Input\n",
    "        original = Input(shape=org_shape)\n",
    "\n",
    "        # Encoding\n",
    "        c1 = conv(original, 16, mp_flag=False)\n",
    "        c2 = conv(c1, 32)\n",
    "\n",
    "        # Encoder\n",
    "        encoded = conv(c2, 64)\n",
    "\n",
    "        # Decoding\n",
    "        x = deconv_unet(encoded, c2, 32)\n",
    "        x = deconv_unet(x, c1, 16)\n",
    "\n",
    "        decoded = Conv2D(n_ch, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "        #decoded = Conv2D(n_ch, (3, 3), padding='same')(x)\n",
    "\n",
    "        super().__init__(original, decoded)\n",
    "        self.compile(optimizer='adadelta', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# 데이타 불러오기\n",
    "###########################\n",
    "from tensorflow.keras import datasets, utils\n",
    "\n",
    "class DATA():\n",
    "    def __init__(self, in_ch=None):\n",
    "        (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "        if x_train.ndim == 4:\n",
    "            if backend.image_data_format() == 'channels_first':\n",
    "                n_ch, img_rows, img_cols = x_train.shape[1:]\n",
    "            else:\n",
    "                img_rows, img_cols, n_ch = x_train.shape[1:]\n",
    "        else:\n",
    "            img_rows, img_cols = x_train.shape[1:]\n",
    "            n_ch = 1\n",
    "        # in_ch can be 1 for changing BW to color image using UNet\n",
    "        in_ch = n_ch if in_ch is None else in_ch\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        def RGB2Gray(X, fmt):\n",
    "            if fmt == 'channels_first':\n",
    "                R = X[:, 0:1]\n",
    "                G = X[:, 1:2]\n",
    "                B = X[:, 2:3]\n",
    "            else:  # \"channels_last\n",
    "                R = X[..., 0:1]\n",
    "                G = X[..., 1:2]\n",
    "                B = X[..., 2:3]\n",
    "            return 0.299 * R + 0.587 * G + 0.114 * B\n",
    "        \n",
    "        def RGB2RG(x_train_out, x_test_out, fmt):\n",
    "            if fmt == 'channels_first':\n",
    "                x_train_in = x_train_out[:, :2]\n",
    "                x_test_in = x_test_out[:, :2]\n",
    "            else:\n",
    "                x_train_in = x_train_out[..., :2]\n",
    "                x_test_in = x_test_out[..., :2]      \n",
    "            return x_train_in, x_test_in\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], n_ch, img_rows, img_cols)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], n_ch, img_rows, img_cols)\n",
    "            input_shape = (in_ch, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], img_rows, img_cols, n_ch)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], img_rows, img_cols, n_ch)\n",
    "            input_shape = (img_rows, img_cols, in_ch)\n",
    "\n",
    "        if in_ch == 1 and n_ch == 3:\n",
    "            x_train_in = RGB2Gray(x_train_out, backend.image_data_format())\n",
    "            x_test_in = RGB2Gray(x_test_out, backend.image_data_format())\n",
    "        elif in_ch == 2 and n_ch == 3:\n",
    "            # print(in_ch, n_ch)\n",
    "            x_train_in, x_test_in = RGB2RG(x_train_out, x_test_out, backend.image_data_format())\n",
    "        else:\n",
    "            x_train_in = x_train_out\n",
    "            x_test_in = x_test_out\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.x_train_in, self.x_train_out = x_train_in, x_train_out\n",
    "        self.x_test_in, self.x_test_out = x_test_in, x_test_out\n",
    "        self.n_ch = n_ch\n",
    "        self.in_ch = in_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 UNET 처리 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# UNET 검증\n",
    "###########################\n",
    "from keraspp.skeras import plot_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "###########################\n",
    "# UNET 동작 확인\n",
    "###########################\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def show_images(data, unet):\n",
    "    x_test_in = data.x_test_in\n",
    "    x_test_out = data.x_test_out\n",
    "    decoded_imgs_org = unet.predict(x_test_in)\n",
    "    decoded_imgs = decoded_imgs_org\n",
    "\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        print(x_test_out.shape)\n",
    "        x_test_out = x_test_out.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        print(x_test_out.shape)\n",
    "        decoded_imgs = decoded_imgs.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[:, 0, ...]\n",
    "        elif data.in_ch == 2:\n",
    "            print(x_test_out.shape)\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "        else:\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "    else:\n",
    "        # x_test_in = x_test_in[..., 0]\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[..., 0]\n",
    "        elif data.in_ch == 2:\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i in range(n):\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1)\n",
    "        if x_test_in.ndim < 4:\n",
    "            plt.imshow(x_test_in[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(x_test_in[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n * 2)\n",
    "        plt.imshow(x_test_out[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.5 UNET 학습 및 결과 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(32, 32, 1) (50000, 32, 32, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 20:44:47.621744: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-31 20:44:48.549219: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 136s 2s/step - loss: 0.0808 - val_loss: 0.0602\n",
      "Epoch 2/10\n",
      " 3/79 [>.............................] - ETA: 2:06 - loss: 0.0748"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 학습 및 확인\n",
    "###########################    \n",
    "def main(in_ch=1, epochs=10, batch_size=512, fig=True):\n",
    "\n",
    "\n",
    "    data = DATA(in_ch=in_ch)\n",
    "    print(data.input_shape, data.x_train_in.shape)\n",
    "    unet = UNET(data.input_shape, data.n_ch)\n",
    "\n",
    "    history = unet.fit(data.x_train_in, data.x_train_out,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       validation_split=0.2)\n",
    "\n",
    "    if fig:\n",
    "        plot_loss(history)\n",
    "        show_images(data, unet)\n",
    "\n",
    "\n",
    "from distutils import util\n",
    "\n",
    "class parser:\n",
    "    def __init__(self):\n",
    "        self.input_channels = 1\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 512\n",
    "        self.fig = True\n",
    "              \n",
    "args = parser()\n",
    "print(args.fig)\n",
    "main(args.input_channels, args.epochs, args.batch_size, args.fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 8.2.6 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function image_data_format at 0x7fbcdbd9ce50>\n",
      "Output_fold is GAN_OUT\n",
      "Epoch is 0\n",
      "Number of batches 2\n",
      "Epoch is 10\n",
      "Number of batches 2\n",
      "Epoch is 20\n",
      "Number of batches 2\n",
      "Epoch is 30\n",
      "Number of batches 2\n",
      "Epoch is 40\n",
      "Number of batches 2\n",
      "Epoch is 50\n",
      "Number of batches 2\n",
      "Epoch is 60\n",
      "Number of batches 2\n",
      "Epoch is 70\n",
      "Number of batches 2\n",
      "Epoch is 80\n",
      "Number of batches 2\n",
      "Epoch is 90\n",
      "Number of batches 2\n",
      "Epoch is 100\n",
      "Number of batches 2\n",
      "Epoch is 110\n",
      "Number of batches 2\n",
      "Epoch is 120\n",
      "Number of batches 2\n",
      "Epoch is 130\n",
      "Number of batches 2\n",
      "Epoch is 140\n",
      "Number of batches 2\n",
      "Epoch is 150\n",
      "Number of batches 2\n",
      "Epoch is 160\n",
      "Number of batches 2\n",
      "Epoch is 170\n",
      "Number of batches 2\n",
      "Epoch is 180\n",
      "Number of batches 2\n",
      "Epoch is 190\n",
      "Number of batches 2\n",
      "Epoch is 200\n",
      "Number of batches 2\n",
      "Epoch is 210\n",
      "Number of batches 2\n",
      "Epoch is 220\n",
      "Number of batches 2\n",
      "Epoch is 230\n",
      "Number of batches 2\n",
      "Epoch is 240\n",
      "Number of batches 2\n",
      "Epoch is 250\n",
      "Number of batches 2\n",
      "Epoch is 260\n",
      "Number of batches 2\n",
      "Epoch is 270\n",
      "Number of batches 2\n",
      "Epoch is 280\n",
      "Number of batches 2\n",
      "Epoch is 290\n",
      "Number of batches 2\n",
      "Epoch is 300\n",
      "Number of batches 2\n",
      "Epoch is 310\n",
      "Number of batches 2\n",
      "Epoch is 320\n",
      "Number of batches 2\n",
      "Epoch is 330\n",
      "Number of batches 2\n",
      "Epoch is 340\n",
      "Number of batches 2\n",
      "Epoch is 350\n",
      "Number of batches 2\n",
      "Epoch is 360\n",
      "Number of batches 2\n",
      "Epoch is 370\n",
      "Number of batches 2\n",
      "Epoch is 380\n",
      "Number of batches 2\n",
      "Epoch is 390\n",
      "Number of batches 2\n",
      "Epoch is 400\n",
      "Number of batches 2\n",
      "Epoch is 410\n",
      "Number of batches 2\n",
      "Epoch is 420\n",
      "Number of batches 2\n",
      "Epoch is 430\n",
      "Number of batches 2\n",
      "Epoch is 440\n",
      "Number of batches 2\n",
      "Epoch is 450\n",
      "Number of batches 2\n",
      "Epoch is 460\n",
      "Number of batches 2\n",
      "Epoch is 470\n",
      "Number of batches 2\n",
      "Epoch is 480\n",
      "Number of batches 2\n",
      "Epoch is 490\n",
      "Number of batches 2\n",
      "Epoch is 500\n",
      "Number of batches 2\n",
      "Epoch is 510\n",
      "Number of batches 2\n",
      "Epoch is 520\n",
      "Number of batches 2\n",
      "Epoch is 530\n",
      "Number of batches 2\n",
      "Epoch is 540\n",
      "Number of batches 2\n",
      "Epoch is 550\n",
      "Number of batches 2\n",
      "Epoch is 560\n",
      "Number of batches 2\n",
      "Epoch is 570\n",
      "Number of batches 2\n",
      "Epoch is 580\n",
      "Number of batches 2\n",
      "Epoch is 590\n",
      "Number of batches 2\n",
      "Epoch is 600\n",
      "Number of batches 2\n",
      "Epoch is 610\n",
      "Number of batches 2\n",
      "Epoch is 620\n",
      "Number of batches 2\n",
      "Epoch is 630\n",
      "Number of batches 2\n",
      "Epoch is 640\n",
      "Number of batches 2\n",
      "Epoch is 650\n",
      "Number of batches 2\n",
      "Epoch is 660\n",
      "Number of batches 2\n",
      "Epoch is 670\n",
      "Number of batches 2\n",
      "Epoch is 680\n",
      "Number of batches 2\n",
      "Epoch is 690\n",
      "Number of batches 2\n",
      "Epoch is 700\n",
      "Number of batches 2\n",
      "Epoch is 710\n",
      "Number of batches 2\n",
      "Epoch is 720\n",
      "Number of batches 2\n",
      "Epoch is 730\n",
      "Number of batches 2\n",
      "Epoch is 740\n",
      "Number of batches 2\n",
      "Epoch is 750\n",
      "Number of batches 2\n",
      "Epoch is 760\n",
      "Number of batches 2\n",
      "Epoch is 770\n",
      "Number of batches 2\n",
      "Epoch is 780\n",
      "Number of batches 2\n",
      "Epoch is 790\n",
      "Number of batches 2\n",
      "Epoch is 800\n",
      "Number of batches 2\n",
      "Epoch is 810\n",
      "Number of batches 2\n",
      "Epoch is 820\n",
      "Number of batches 2\n",
      "Epoch is 830\n",
      "Number of batches 2\n",
      "Epoch is 840\n",
      "Number of batches 2\n",
      "Epoch is 850\n",
      "Number of batches 2\n",
      "Epoch is 860\n",
      "Number of batches 2\n",
      "Epoch is 870\n",
      "Number of batches 2\n",
      "Epoch is 880\n",
      "Number of batches 2\n",
      "Epoch is 890\n",
      "Number of batches 2\n",
      "Epoch is 900\n",
      "Number of batches 2\n",
      "Epoch is 910\n",
      "Number of batches 2\n",
      "Epoch is 920\n",
      "Number of batches 2\n",
      "Epoch is 930\n",
      "Number of batches 2\n",
      "Epoch is 940\n",
      "Number of batches 2\n",
      "Epoch is 950\n",
      "Number of batches 2\n",
      "Epoch is 960\n",
      "Number of batches 2\n",
      "Epoch is 970\n",
      "Number of batches 2\n",
      "Epoch is 980\n",
      "Number of batches 2\n",
      "Epoch is 990\n",
      "Number of batches 2\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# unet_conv_cifar10rgb_mc.py\n",
    "# Convlutional Layer UNET with RGB Cifar10 dataset and Class with Keras Model approach\n",
    "#######################################################################################\n",
    "#import matplotlib\n",
    "#matplotlib.use(\"TkAgg\")\n",
    "\n",
    "###########################\n",
    "# AE 모델링\n",
    "###########################\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import models, backend\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, \\\n",
    "    UpSampling2D, BatchNormalization, Concatenate, Activation\n",
    "\n",
    "# backend.set_image_data_format('channels_first')\n",
    "\n",
    "class UNET(models.Model):\n",
    "    def __init__(self, org_shape, n_ch):\n",
    "        ic = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "        def conv(x, n_f, mp_flag=True):\n",
    "            x = MaxPooling2D((2, 2), padding='same')(x) if mp_flag else x\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            x = Dropout(0.05)(x)\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            return x\n",
    "\n",
    "        def deconv_unet(x, e, n_f):\n",
    "            x = UpSampling2D((2, 2))(x)\n",
    "            x = Concatenate(axis=ic)([x, e])\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            x = Conv2D(n_f, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            return x\n",
    "\n",
    "        # Input\n",
    "        original = Input(shape=org_shape)\n",
    "\n",
    "        # Encoding\n",
    "        c1 = conv(original, 16, mp_flag=False)\n",
    "        c2 = conv(c1, 32)\n",
    "\n",
    "        # Encoder\n",
    "        encoded = conv(c2, 64)\n",
    "\n",
    "        # Decoding\n",
    "        x = deconv_unet(encoded, c2, 32)\n",
    "        x = deconv_unet(x, c1, 16)\n",
    "\n",
    "        decoded = Conv2D(n_ch, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "        #decoded = Conv2D(n_ch, (3, 3), padding='same')(x)\n",
    "\n",
    "        super().__init__(original, decoded)\n",
    "        self.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "\n",
    "###########################\n",
    "# 데이타 불러오기\n",
    "###########################\n",
    "from tensorflow.keras import datasets, utils\n",
    "\n",
    "class DATA():\n",
    "    def __init__(self, in_ch=None):\n",
    "        (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "        if x_train.ndim == 4:\n",
    "            if backend.image_data_format() == 'channels_first':\n",
    "                n_ch, img_rows, img_cols = x_train.shape[1:]\n",
    "            else:\n",
    "                img_rows, img_cols, n_ch = x_train.shape[1:]\n",
    "        else:\n",
    "            img_rows, img_cols = x_train.shape[1:]\n",
    "            n_ch = 1\n",
    "        # in_ch can be 1 for changing BW to color image using UNet\n",
    "        in_ch = n_ch if in_ch is None else in_ch\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        def RGB2Gray(X, fmt):\n",
    "            if fmt == 'channels_first':\n",
    "                R = X[:, 0:1]\n",
    "                G = X[:, 1:2]\n",
    "                B = X[:, 2:3]\n",
    "            else:  # \"channels_last\n",
    "                R = X[..., 0:1]\n",
    "                G = X[..., 1:2]\n",
    "                B = X[..., 2:3]\n",
    "            return 0.299 * R + 0.587 * G + 0.114 * B\n",
    "        \n",
    "        def RGB2RG(x_train_out, x_test_out, fmt):\n",
    "            if fmt == 'channels_first':\n",
    "                x_train_in = x_train_out[:, :2]\n",
    "                x_test_in = x_test_out[:, :2]\n",
    "            else:\n",
    "                x_train_in = x_train_out[..., :2]\n",
    "                x_test_in = x_test_out[..., :2]      \n",
    "            return x_train_in, x_test_in\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], n_ch, img_rows, img_cols)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], n_ch, img_rows, img_cols)\n",
    "            input_shape = (in_ch, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], img_rows, img_cols, n_ch)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], img_rows, img_cols, n_ch)\n",
    "            input_shape = (img_rows, img_cols, in_ch)\n",
    "\n",
    "        if in_ch == 1 and n_ch == 3:\n",
    "            x_train_in = RGB2Gray(x_train_out, backend.image_data_format())\n",
    "            x_test_in = RGB2Gray(x_test_out, backend.image_data_format())\n",
    "        elif in_ch == 2 and n_ch == 3:\n",
    "            # print(in_ch, n_ch)\n",
    "            x_train_in, x_test_in = RGB2RG(x_train_out, x_test_out, backend.image_data_format())\n",
    "        else:\n",
    "            x_train_in = x_train_out\n",
    "            x_test_in = x_test_out\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.x_train_in, self.x_train_out = x_train_in, x_train_out\n",
    "        self.x_test_in, self.x_test_out = x_test_in, x_test_out\n",
    "        self.n_ch = n_ch\n",
    "        self.in_ch = in_ch\n",
    "\n",
    "\n",
    "###########################\n",
    "# UNET 검증\n",
    "###########################\n",
    "from keraspp.skeras import plot_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "###########################\n",
    "# UNET 동작 확인\n",
    "###########################\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def show_images(data, unet):\n",
    "    x_test_in = data.x_test_in\n",
    "    x_test_out = data.x_test_out\n",
    "    decoded_imgs_org = unet.predict(x_test_in)\n",
    "    decoded_imgs = decoded_imgs_org\n",
    "\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        print(x_test_out.shape)\n",
    "        x_test_out = x_test_out.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        print(x_test_out.shape)\n",
    "        decoded_imgs = decoded_imgs.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[:, 0, ...]\n",
    "        elif data.in_ch == 2:\n",
    "            print(x_test_out.shape)\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "        else:\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "    else:\n",
    "        # x_test_in = x_test_in[..., 0]\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[..., 0]\n",
    "        elif data.in_ch == 2:\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i in range(n):\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1)\n",
    "        if x_test_in.ndim < 4:\n",
    "            plt.imshow(x_test_in[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(x_test_in[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n * 2)\n",
    "        plt.imshow(x_test_out[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "###########################\n",
    "# 학습 및 확인\n",
    "###########################    \n",
    "def main(in_ch=1, epochs=10, batch_size=512, fig=True):\n",
    "\n",
    "\n",
    "    data = DATA(in_ch=in_ch)\n",
    "    print(data.input_shape, data.x_train_in.shape)\n",
    "    unet = UNET(data.input_shape, data.n_ch)\n",
    "\n",
    "    history = unet.fit(data.x_train_in, data.x_train_out,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       validation_split=0.2)\n",
    "\n",
    "    if fig:\n",
    "        plot_loss(history)\n",
    "        show_images(data, unet)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    from distutils import util\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='UNET for Cifar-10: Gray to RGB')\n",
    "    parser.add_argument('--input_channels', type=int, default=1,\n",
    "                        help='input channels (default: 1)')\n",
    "    parser.add_argument('--epochs', type=int, default=10,\n",
    "                        help='training epochs (default: 10)')\n",
    "    parser.add_argument('--batch_size', type=int, default=512,\n",
    "                        help='batch size (default: 1000)')\n",
    "    parser.add_argument('--fig', type=lambda x: bool(util.strtobool(x)),\n",
    "                        default=True, help='flag to show figures (default: True)')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"Aargs:\", args)\n",
    "\n",
    "    print(args.fig)\n",
    "    main(args.input_channels, args.epochs, args.batch_size, args.fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras2",
   "language": "python",
   "name": "keras2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
