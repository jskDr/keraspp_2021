{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 텐서플로 함수 활용하기  \n",
    "새로운 구능 기현시 유연하게 대처하는 방법으로 텐서플로와 케라스를 섞어 쓰는 방법을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to use CPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.1 텐서플로와 케라스 패키지 임포트 및 상호 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.2 완전 연결층 인공지능망 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "\n",
    "class DNN(Model):\n",
    "    def __init__(self, Nin=2, Nh_l=[2,2], Nout=2):\n",
    "        super(DNN, self).__init__()\n",
    "        self.dense1 = Dense(Nh_l[0], activation='relu')\n",
    "        self.dense2 = Dense(Nh_l[1], activation='relu')\n",
    "        self.dense3 = Dense(Nout, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = self.dense2(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        return self.dense3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.3 데이터 준비 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets  # mnist\n",
    "from keras.utils import np_utils  # to_categorical\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    #Y_train = np_utils.to_categorical(y_train)\n",
    "    #Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, H, W = X_train.shape\n",
    "    X_train = X_train.reshape(-1, H * W)\n",
    "    X_test = X_test.reshape(-1, H * W)\n",
    "\n",
    "    X_train = (X_train / 255.0).astype(np.float32)\n",
    "    X_test = (X_test / 255.0).astype(np.float32)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5.4 학습 진행 및 효과 분석 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 00:16:13.139362: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.654, Accuracy: 79.7, Test Loss: 0.225, Test Accuracy: 93.2\n",
      "Epoch 1, Loss: 0.499, Accuracy: 84.8, Test Loss: 0.2, Test Accuracy: 93.9\n",
      "Epoch 2, Loss: 0.427, Accuracy: 87.1, Test Loss: 0.184, Test Accuracy: 94.4\n",
      "Epoch 3, Loss: 0.383, Accuracy: 88.5, Test Loss: 0.173, Test Accuracy: 94.8\n",
      "Epoch 4, Loss: 0.352, Accuracy: 89.5, Test Loss: 0.164, Test Accuracy: 95.0\n",
      "Epoch 5, Loss: 0.329, Accuracy: 90.2, Test Loss: 0.156, Test Accuracy: 95.3\n",
      "Epoch 6, Loss: 0.311, Accuracy: 90.7, Test Loss: 0.15, Test Accuracy: 95.5\n",
      "Epoch 7, Loss: 0.296, Accuracy: 91.2, Test Loss: 0.145, Test Accuracy: 95.6\n",
      "Epoch 8, Loss: 0.283, Accuracy: 91.6, Test Loss: 0.142, Test Accuracy: 95.7\n",
      "Epoch 9, Loss: 0.273, Accuracy: 91.9, Test Loss: 0.138, Test Accuracy: 95.8\n"
     ]
    }
   ],
   "source": [
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "#  Nin=2, Nh_l=[2,2], Nout=2)\n",
    "Nin = 784\n",
    "Nh_l = [100, 50]\n",
    "number_of_class = 10\n",
    "Nout = number_of_class\n",
    "\n",
    "data = Data_func()\n",
    "model = DNN(Nin, Nh_l, Nout)\n",
    "batch_size = 100\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = data\n",
    "X_train.shape, Y_train.shape\n",
    "\n",
    "N_tr = X_train.shape[0]\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for b in range(N_tr // batch_size):\n",
    "        X_tr_b = X_train[batch_size * (b-1):batch_size * b]\n",
    "        Y_tr_b = Y_train[batch_size * (b-1):batch_size * b]\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(X_tr_b, training=True)\n",
    "            loss = loss_object(Y_tr_b, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        train_accuracy(Y_tr_b, predictions)\n",
    "        \n",
    "    predictions = model(X_test, training=False)\n",
    "    t_loss = loss_object(Y_test, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(Y_test, predictions)\n",
    "        \n",
    "    print(\n",
    "        f'Epoch {epoch}, '\n",
    "        f'Loss: {train_loss.result():.3}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100:.3}, '\n",
    "        f'Test Loss: {test_loss.result():.3}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 9.2.7 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras2",
   "language": "python",
   "name": "keras2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
